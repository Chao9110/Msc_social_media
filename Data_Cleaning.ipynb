{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning complete! Remaining records: 7733\n",
      "Removed 0 records, accounting for 0.00% of the data.\n",
      "                                               title  \\\n",
      "0               [acne] A year after stopping Cerave    \n",
      "1             [Review] CeraVe products love or hate?   \n",
      "2  [B&A] A week ago I discovered this sub and dis...   \n",
      "3  For all you CeraVe haters, what did CeraVe do ...   \n",
      "4  [Product Question] Are Cerave products still w...   \n",
      "5                      [Acne] is CeraVe really good?   \n",
      "6  [PSA] I received this notice from Amazon that ...   \n",
      "7  [Misc] CVS is not even trying to be subtle wit...   \n",
      "8  [PSA] Being sold through the CeraVe Amazon sto...   \n",
      "9  [acne] breakouts using Cerave moisturizer vs. ...   \n",
      "\n",
      "                                            comments  \n",
      "0                                                     \n",
      "1                                                     \n",
      "2                                                     \n",
      "3                                                     \n",
      "4                                                     \n",
      "5                                                     \n",
      "6                                                     \n",
      "7                                                     \n",
      "8   media items like CDs and books do not qualify...  \n",
      "9                                                     \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"data/CeraVe_reddit_full_data_V2.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the original number of records\n",
    "original_count = len(df)\n",
    "\n",
    "# Select relevant columns\n",
    "columns_to_keep = [\"title\", \"text\", \"upvotes\", \"comments\", \"timestamp\", \"url\", \"subreddit\", \"keyword\"]\n",
    "df = df[columns_to_keep]\n",
    "\n",
    "# Remove missing values\n",
    "df.dropna(subset=[\"title\"], inplace=True)\n",
    "\n",
    "# Drop duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Convert to string, avoid issues with NaN values\n",
    "df[\"comments\"] = df[\"comments\"].astype(str).fillna(\"\")\n",
    "df[\"text\"] = df[\"text\"].astype(str).fillna(\"\")\n",
    "\n",
    "# Timestamp\n",
    "def convert_timestamp(value):\n",
    "    try:\n",
    "        if isinstance(value, (int, float)) and value > 1000000000:  # Unix timestamp check\n",
    "            return pd.to_datetime(value, unit='s')\n",
    "        else:\n",
    "            return pd.to_datetime(value, errors='coerce')  # Convert or assign NaT\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "df[\"timestamp\"] = df[\"timestamp\"].apply(convert_timestamp)\n",
    "\n",
    "# Define machine-generated content patterns\n",
    "bot_keywords = [\"bot\", \"automoderator\"]\n",
    "\n",
    "# Function to check if text contains bot-related keywords\n",
    "def is_machine_generated(text):\n",
    "    return any(keyword in text.lower() for keyword in bot_keywords)\n",
    "\n",
    "# Remove machine-generated content from 'comments' and 'text' without deleting the entire row\n",
    "df[\"comments\"] = df[\"comments\"].apply(lambda x: \"\" if is_machine_generated(x) else x)\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: \"\" if is_machine_generated(x) else x)\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Function to filter CeraVe-related comments\n",
    "def filter_cerave_comments(comments):\n",
    "    if pd.isna(comments) or comments.strip() == \"\":  \n",
    "        return \"\"\n",
    "    lines = comments.split(\",\")  \n",
    "    filtered_lines = [line for line in lines if \"cerave\" in line.lower()]\n",
    "    return \"\\n\".join(filtered_lines) if filtered_lines else \"\"\n",
    "\n",
    "# Apply filtering only if 'cerave' is NOT in the title\n",
    "df[\"comments\"] = df[\"comments\"].map(filter_cerave_comments)\n",
    "\n",
    "# Replace NaN values and reset index\n",
    "df[\"comments\"].replace([\"nan\", \"NaN\"], \"\", inplace=True)\n",
    "df[\"text\"].replace([\"nan\", \"NaN\"], \"\", inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save the cleaned dataset\n",
    "cleaned_file_path = \"data/CeraVe_reddit_cleaned_data_V2.csv\"\n",
    "df.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "# Display statistics about removed data\n",
    "cleaned_count = len(df)\n",
    "removed_count = original_count - cleaned_count\n",
    "removed_percentage = (removed_count / original_count) * 100\n",
    "\n",
    "print(f\"Cleaning complete! Remaining records: {cleaned_count}\")\n",
    "print(f\"Removed {removed_count} records, accounting for {removed_percentage:.2f}% of the data.\")\n",
    "print(df[[\"title\", \"comments\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Missing Values Per Column:\n",
      "text        1987\n",
      "comments    6618\n",
      "dtype: int64\n",
      "\n",
      " Duplicate Rows: 0\n",
      "\n",
      " Data Types:\n",
      "title        object\n",
      "text         object\n",
      "upvotes       int64\n",
      "comments     object\n",
      "timestamp    object\n",
      "url          object\n",
      "subreddit    object\n",
      "keyword      object\n",
      "dtype: object\n",
      "\n",
      " Empty Strings Per Column:\n",
      "Series([], dtype: int64)\n",
      "\n",
      " Outlier Analysis (Numeric Columns):\n",
      "            upvotes\n",
      "count   7733.000000\n",
      "mean     142.892668\n",
      "std     1015.610470\n",
      "min        0.000000\n",
      "25%        1.000000\n",
      "50%        3.000000\n",
      "75%       15.000000\n",
      "95%      550.000000\n",
      "99%     3050.680000\n",
      "max    63235.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load the cleaned dataset\n",
    "file_path = \"data/Cerave_reddit_cleaned_data_V2.csv\"  \n",
    "df = pd.read_csv(file_path)\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Check for duplicate rows\n",
    "duplicate_rows = df.duplicated().sum()\n",
    "\n",
    "# Check data types\n",
    "data_types = df.dtypes\n",
    "\n",
    "# Check for empty strings after cleaning\n",
    "empty_strings = (df == '').sum()\n",
    "\n",
    "# Check for outliers in numeric columns\n",
    "numeric_cols = df.select_dtypes(include=['number'])\n",
    "outliers = numeric_cols.describe(percentiles=[0.25, 0.5, 0.75, 0.95, 0.99])\n",
    "\n",
    "# Display results\n",
    "print(\" Missing Values Per Column:\")\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "print(\"\\n Duplicate Rows:\", duplicate_rows)\n",
    "\n",
    "print(\"\\n Data Types:\")\n",
    "print(data_types)\n",
    "\n",
    "print(\"\\n Empty Strings Per Column:\")\n",
    "print(empty_strings[empty_strings > 0])\n",
    "\n",
    "print(\"\\n Outlier Analysis (Numeric Columns):\")\n",
    "print(outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning complete! Remaining records: 4518\n",
      "                                               title  \\\n",
      "0               [acne] A year after stopping Cerave    \n",
      "1             [Review] CeraVe products love or hate?   \n",
      "2  [B&A] A week ago I discovered this sub and dis...   \n",
      "3  For all you CeraVe haters, what did CeraVe do ...   \n",
      "4  [Product Question] Are Cerave products still w...   \n",
      "5                      [Acne] is CeraVe really good?   \n",
      "6  [PSA] I received this notice from Amazon that ...   \n",
      "7  [Misc] CVS is not even trying to be subtle wit...   \n",
      "8  [PSA] Being sold through the CeraVe Amazon sto...   \n",
      "9  [acne] breakouts using Cerave moisturizer vs. ...   \n",
      "\n",
      "                                              tokens  \n",
      "0                [acne, year, stopping, cerave, nan]  \n",
      "1        [review, cerave, products, love, hate, nan]  \n",
      "2  [ba, week, ago, discovered, sub, discontinued,...  \n",
      "3  [cerave, haters, cerave, skin, use, product, q...  \n",
      "4  [product, question, cerave, products, still, d...  \n",
      "5  [acne, cerave, really, good, tried, sample, fo...  \n",
      "6  [psa, received, notice, amazon, cerave, produc...  \n",
      "7  [misc, cvs, even, trying, subtle, lrp, cerave,...  \n",
      "8  [psa, sold, cerave, amazon, store, doesnt, mea...  \n",
      "9  [acne, breakouts, using, cerave, moisturizer, ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "file_path = \"data/Cerave_reddit_cleaned_data_V2.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Select relevant columns\n",
    "columns_to_keep = [\"title\", \"text\", \"upvotes\", \"comments\", \"timestamp\", \"url\", \"subreddit\", \"keyword\"]\n",
    "df = df[columns_to_keep]\n",
    "\n",
    "# Remove missing values in title (title is required)\n",
    "df.dropna(subset=[\"title\"], inplace=True)\n",
    "\n",
    "# Keep only one instance if there are duplicates in title and text\n",
    "df.drop_duplicates(subset=[\"title\", \"text\"], keep=\"first\", inplace=True)\n",
    "\n",
    "# Convert 'comments' and 'text' to string and fill NaN values\n",
    "df[\"comments\"] = df[\"comments\"].astype(str).fillna(\"\")\n",
    "df[\"text\"] = df[\"text\"].astype(str).fillna(\"\")\n",
    "\n",
    "# Convert timestamp\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
    "\n",
    "# Remove bot-generated content from 'comments' and 'text' without deleting the row\n",
    "bot_keywords = [\"bot\", \"automoderator\"]\n",
    "def is_machine_generated(text):\n",
    "    return any(keyword in text.lower() for keyword in bot_keywords)\n",
    "\n",
    "df[\"comments\"] = df[\"comments\"].apply(lambda x: \"\" if is_machine_generated(x) else x)\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: \"\" if is_machine_generated(x) else x)\n",
    "# Remove URLs from text\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: re.sub(r'http\\S+|www\\S+', '', x))\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Combine 'title' and 'text' for NLP analysis**\n",
    "df[\"full_text\"] = df[\"title\"].fillna(\"\") + \" \" + df[\"text\"].fillna(\"\")\n",
    "\n",
    "# clean text**\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    tokens = word_tokenize(text)  # Tokenize words\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]  # Remove stopwords\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# Apply\n",
    "df[\"tokens\"] = df[\"full_text\"].apply(clean_text)\n",
    "\n",
    "# Save \n",
    "cleaned_file_path = \"data/CeraVe_reddit_cleaned_data_V3.csv\"\n",
    "df.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "# Display \n",
    "cleaned_count = len(df)\n",
    "print(f\"Cleaning complete! Remaining records: {cleaned_count}\")\n",
    "print(df[[\"title\", \"tokens\"]].head(10))  # Show first 10 rows for verification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# select time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records before filtering: 4518\n",
      "Total records after filtering (last 5 years): 4006\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "file_path = \"data/CeraVe_reddit_cleaned_data_V3.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")  \n",
    "\n",
    "current_year = datetime.now().year \n",
    "start_date = datetime(current_year - 5, 1, 1)  # 2020-01-01\n",
    "\n",
    "df_filtered = df[df[\"timestamp\"] >= start_date]\n",
    "\n",
    "filtered_file_path = \"data/CeraVe_reddit_filtered_last_5_years.csv\"\n",
    "df_filtered.to_csv(filtered_file_path, index=False)\n",
    "\n",
    "print(f\"Total records before filtering: {len(df)}\")\n",
    "print(f\"Total records after filtering (last 5 years): {len(df_filtered)}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
